# Kafka
Kafka是一个开源的分布式消息引擎系统，它主要提供一套完备的消息发布与订阅的解决方案

## 主题(Topic)
在 Kafka 中，发布订阅的对象是主题（Topic），你可以为每
个业务、每个应用甚至是每类数据都创建专属的主题。


## 生产者(Producer)和消费者(Consumer)
向主题发布消息的客户端应用程序称为生产者（Producer），生产者程序通常持续不断地向一个或多个主题发送消息，而订阅这些主题消息的客户端应用程序就被称为消费者（Consumer）。

## 客户端和服务端
我们把生产者和消费者统称为客户端（Clients）。你可以同时运行多个生产者和消费者实例，这些实例会不断地向 Kafka 集群中的多个主题生产和消费消息。    


有客户端自然也就有服务器端。Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。    

虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将
不同的 Broker 分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一。    

实现高可用的另一个手段就是备份机制（Replication）。备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在 Kafka 中被称为副本（Replica）。Kafka 定义了两类副本：领导者副本（Leader
Replica）和追随者副本（Follower Replica）。前者对外提供服务，这里的对外指的是与客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互。当然了，你可能知道在很多其他系统中追随者副本是可以对外提供服务的，比如 MySQL 的从库是可以处理读操作的，但是在 Kafka 中追随者副本不会对外提供服务。

副本的工作机制也很简单：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。    

如果领导者副本积累了太多的数据导致单台的Broker机器无法容纳，Kafka就会把数据分割成多份保存在不同的Broker上，这种机制就是所谓的分区(Partition)。    

Kafka 中的分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，这条消息要么在分区 0 中，要么在分区 1 中。如你所见，Kafka的分区编号是从 0 开始的，如果 Topic 有 100 个分区，那么它们的分区号就是从 0 到99。每个分区可以有多个副本

## Kafka的三层消息架构
- 主题层：每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本
- 分区层: 每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用
- 消息层: 分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。
最后，客户端程序只能与分区的领导者副本进行交互。

## Kafka持久化数据
Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。   

Kafka删除消息是通过日志段（Log Segment）机制。在 Kafka 底层，一
个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。

## 消息模型
- 点对点模型：同一条消息只能被下游的一个消费者消费，其它消费者不能染指
- 消费者位移(Consumer Offset): 每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上, 这个字段就是消费者位移。

## 参数

### Broker端参数

- log.dirs: 指定了Broker需要使用地若干个文件目录路径
- log.dir: 指定Broker使用地单个路径    
这两个参数应该怎么设置呢？很简单，你只要设置log.dirs，即第一个参数就好了，不要设置log.dir。而且重要的是，在线上生产环境中一定要log.dirs配置多个路径，具体格式是一个 CSV 格式，也就是用逗号分隔的多个路径，比如/home/kafka1,/home/kafka2,/home/kafka3这样。如果有条件地话最好保证这些目录挂载到不同地物理磁盘上，这样做有两个好处：     


提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。        
能够实现故障转移：即 Failover。这是 Kafka 1.1 版本新引入的强大功能。要知道在以前，只要 Kafka Broker 使用的任何一块磁盘挂掉了整个 Broker 进程都会关闭。但是自 1.1 开始，这种情况被修正了，坏掉的磁盘上的数据会自动地转移到其他正常的磁盘上，而且 Broker 还能正常工作。还记得上一期我们关于 Kafka 是否需要使用RAID 的讨论吗？这个改进正是我们舍弃 RAID 方案的基础：没有这种 Failover 的话，我们只能依靠 RAID 来提供保障。

Broker 连接相关的，即客户端程序或其他Broker如何与该 Broker 进行通信的设置。有以下三个参数：
- listeners: 告诉外部连接者要通过什么协议访问指定主机名和端口开放的 Kafka 服务。
- advertised.listeners: 对外公布地监听器
- host.name/port: 主机名和端口    


关于 Topic 管理的。我来讲讲下面这三个参数：
- auto.create.topics.enable: 是否允许自动创建topic，一般设置为false
- unclean.leader.election.enable: 是否允许Unclean Leader选举, 如果设置为false，则不允许数据量太少地副本参加竞选leader副本；如果是true的话，则允许，但这有可能会导致数据丢失。
- auto.leader.rebalance.enable: 是否允许定期进行Leader更换    

关于数据留存方面的参数:
- log.retention.{hour|minutes|ms}: 控制一条数据被保存多长时间。从优先级来说ms设置最高，minutes次之，hour最低，但是一般设置hour的级别比较多
- log.retention.bytes: 指定Broker为消息保存的总磁盘大小，默认值为-1, 表示在这台Broker上保存多少数据都可以。
- message.max.bytes: 控制Broker能够接收的最大消息大小    

关于Zookeeper相关设置：
首先Zookeeper是一个分布式协调框架，负责协调管理并保存Kafka集群的所有元数据信息，比如集群都有哪些Broker在运行、创建了哪些Topic, 每个Topic都有多少分区以及分区的Leader副本都在哪些机器上等信息。

Kafka 与 ZooKeeper 相关的最重要的参数当属`zookeeper.connect`。这也是一个 CSV 格式的参数，比如我可以指定它的值为zk1:2181,zk2:2181,zk3:2181。2181 是 ZooKeeper的默认端口。    

如果我让多个 Kafka 集群使用同一套ZooKeeper 集群，那么这个参数应该怎么设置呢？这时候chroot 就派上用场了。这个 chroot 是 ZooKeeper 的概念，类似于别名。如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和kafka2，那么两套集群的zookeeper.connect参数可以这样指定：zk1:2181,zk2:2181,zk3:2181/kafka1和zk1:2181,zk2:2181,zk3:2181/kafka2。切记 chroot只需要写一次，而且是加到最后的。

### Topic级别参数

如果同时设置了 Topic 级别参数和全局 Broker 参数，到底听谁的呢？哪个说了算呢？答案就是 Topic 级别参数会覆盖全局Broker 参数的值，而每个 Topic 都能设置自己的参数值，这就是所谓的 Topic 级别参数   


